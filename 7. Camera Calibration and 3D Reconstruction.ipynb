{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<h1 style=\"color:blue;\"> Camera Calibration and 3D Reconstruction </h1>\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "\n",
    "# Camera Calibration\n",
    "The everyday used pinhole cameras introduce a lot of distortion to images. Two major distortions are radial distortion and tangential distortion.\n",
    "\n",
    "Due to radial distortion, straight lines will appear curved. Its effect is more as we move away from the center of image. For example, one image is shown below, where two edges of a chess board are marked with red lines. But you can see that border is not a straight line and doesn't match with the red line. All the expected straight lines are bulged out.\n",
    "<img src=\"images/calib_radial.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "To understand these distortions in depth and get a matematical understanding, you can visit: <a href=\"https://en.wikipedia.org/wiki/Distortion_%28optics%29\">Distortion(optics)</a>\n",
    "\n",
    "For the stereo applications, these distortions need to be corrected first. To find the intrinsic and extrinsic parameters of camera, we have to provide some sample images of a well defined pattern like a chess board. We find some specific points in it ( square corners in chess board). We know its coordinates in real world space and we know its coordinates in image. With these data, some mathematical problem is solved in background to get the distortion coefficients. For better results, we need atleast 10 test patterns.\n",
    "\n",
    "We will use the image of chess board (see samples/cpp/left01.jpg â€“ left14.jpg) that come with OpenCV istelf.\n",
    "\n",
    "Example image is shown below:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "<img src=\"images/left08.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Important input datas needed for camera calibration is a set of 3D real world points and its corresponding 2D image points. 2D image points are OK which we can easily find from the image. (These image points are locations where two black squares touch each other in chess boards)\n",
    "\n",
    "What about the 3D points from real world space? Those images are taken from a static camera and chess boards are placed at different locations and orientations. So we need to know (X,Y,Z) values. But for simplicity, we can say chess board was kept stationary at XY plane, (so Z=0 always) and camera was moved accordingly. This consideration helps us to find only X,Y values. Now for X,Y values, we can simply pass the points as (0,0), (1,0), (2,0), ... which denotes the location of points. In this case, the results we get will be in the scale of size of chess board square. But if we know the square size, (say 30 mm), and we can pass the values as (0,0),(30,0),(60,0),..., we get the results in mm.\n",
    "\n",
    "3D points are called object points and 2D image points are called image points.\n",
    "\n",
    "So to find pattern in chess board, we use the function, <a href=\"http://docs.opencv.org/3.0.0/d9/d0c/group__calib3d.html#ga93efa9b0aa890de240ca32b11253dd4a\">cv2.findChessboardCorners()</a>. We also need to pass what kind of pattern we are looking, like 8x8 grid, 5x5 grid etc. In this example, we use 7x6 grid. (Normally a chess board has 8x8 squares and 7x7 internal corners). It returns the corner points and retval which will be True if pattern is obtained. These corners will be placed in an order (from left-to-right, top-to-bottom)\n",
    "\n",
    "\n",
    "This function may not be able to find the required pattern in all the images. So one good option is to write the code such that, it starts the camera and check each frame for required pattern. Once pattern is obtained, find the corners and store it in a list. Also provides some interval before reading next frame so that we can adjust our chess board in different direction. Continue this process until required number of good patterns are obtained. Even in the example provided here, we are not sure out of 14 images given, how many are good. So we read all the images and take the good ones.\n",
    "Instead of chess board, we can use some circular grid, but then use the function _cv2.findCirclesGrid()_ to find the pattern. It is said that less number of images are enough when using circular grid.\n",
    "Once we find the corners, we can increase their accuracy using <a href=\"http://docs.opencv.org/3.0.0/dd/d1a/group__imgproc__feature.html#ga354e0d7c86d0d9da75de9b9701a9a87e\">cv2.cornerSubPix()</a>. We can also draw the pattern using <a href=\"http://docs.opencv.org/3.0.0/d9/d0c/group__calib3d.html#ga6a10b0bb120c4907e5eabbcd22319022\">cv2.drawChessboardCorners()</a>. All these steps are included in below code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "\n",
    "# termination criteria\n",
    "criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 30, 0.001)\n",
    "\n",
    "# prepare object points, like (0,0,0), (1,0,0), (2,0,0) ....,(6,5,0)\n",
    "objp = np.zeros((6*7,3), np.float32)\n",
    "objp[:,:2] = np.mgrid[0:7,0:6].T.reshape(-1,2)\n",
    "\n",
    "# Arrays to store object points and image points from all the images.\n",
    "objpoints = [] # 3d point in real world space\n",
    "imgpoints = [] # 2d points in image plane.\n",
    "\n",
    "# You'll have to store the chessboard images in the directory of this script\n",
    "images = glob.glob('*.jpg')\n",
    "\n",
    "for fname in images:\n",
    "    img = cv2.imread(fname)\n",
    "    gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Find the chess board corners\n",
    "    ret, corners = cv2.findChessboardCorners(gray, (7,6),None)\n",
    "    \n",
    "    # If found, add object points, image points (after refining them)\n",
    "    if ret == True:\n",
    "        objpoints.append(objp)\n",
    "        corners2 = cv2.cornerSubPix(gray,corners,(11,11),(-1,-1),criteria)\n",
    "        imgpoints.append(corners2)\n",
    "        \n",
    "        # Draw and display the corners\n",
    "        img = cv2.drawChessboardCorners(img, (7,6), corners2,ret)\n",
    "        cv2.imshow('img',img)\n",
    "        cv2.waitKey(500)\n",
    "        \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "One image with pattern drawn on it is shown below:\n",
    "<img src=\"images/calib_pattern.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Calibration:\n",
    "\n",
    "So now we have our object points and image points we are ready to go for calibration. For that we use the function, <a href=\"http://docs.opencv.org/3.0.0/d9/d0c/group__calib3d.html#ga687a1ab946686f0d85ae0363b5af1d7b\">cv2.calibrateCamera()</a>. It returns the camera matrix, distortion coefficients, rotation and translation vectors etc.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, gray.shape[::-1],None,None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Undistortion:\n",
    "\n",
    "We have got what we were trying. Now we can take an image and undistort it. OpenCV comes with two methods, we will see both. But before that, we can refine the camera matrix based on a free scaling parameter using <a href=\"http://docs.opencv.org/3.0.0/d9/d0c/group__calib3d.html#ga7a6c4e032c97f03ba747966e6ad862b1\">cv2.getOptimalNewCameraMatrix()</a>. If the scaling parameter alpha=0, it returns undistorted image with minimum unwanted pixels. So it may even remove some pixels at image corners. If alpha=1, all pixels are retained with some extra black images. It also returns an image ROI which can be used to crop the result.\n",
    "\n",
    "So we take a new image (left12.jpg in this case. That is the first image in this chapter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "img = cv2.imread('left12.jpg')\n",
    "h, w = img.shape[:2]\n",
    "newcameramtx, roi=cv2.getOptimalNewCameraMatrix(mtx,dist,(w,h),1,(w,h))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 1. Using cv2.undistort()\n",
    "\n",
    "This is the shortest path. Just call the function and use ROI obtained above to crop the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# undistort\n",
    "dst = cv2.undistort(img, mtx, dist, None, newcameramtx)\n",
    "# crop the image\n",
    "x,y,w,h = roi\n",
    "dst = dst[y:y+h, x:x+w]\n",
    "cv2.imwrite('calibresult.png',dst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 2. Using remapping\n",
    "\n",
    "This is curved path. First find a mapping function from distorted image to undistorted image. Then use the remap function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# undistort\n",
    "mapx,mapy = cv2.initUndistortRectifyMap(mtx,dist,None,newcameramtx,(w,h),5)\n",
    "dst = cv2.remap(img,mapx,mapy,cv2.INTER_LINEAR)\n",
    "# crop the image\n",
    "x,y,w,h = roi\n",
    "dst = dst[y:y+h, x:x+w]\n",
    "cv2.imwrite('calibresult.png',dst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Both the methods give the same result. See the result below:\n",
    "<img src=\"images/calib_result.jpg\">\n",
    "\n",
    "You can see in the result that all the edges are straight.\n",
    "\n",
    "Now you can store the camera matrix and distortion coefficients using write functions in Numpy (np.savez, np.savetxt etc) for future uses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "Following is the complete script that implements camera calibration for distorted images with chess board samples.\n",
    "It reads distorted images, calculates the calibration and write undistorted images to a folder nameed 'output'.\n",
    "\n",
    "#### usage:\n",
    "    ```calibrate.py [--debug <output path>] [--square_size] [<image mask>]```\n",
    "\n",
    "#### default values:\n",
    "    --debug:    ./output/\n",
    "    --square_size: 1.0\n",
    "    <image mask> defaults to ../data/left*.jpg\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### calibrate.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# Python 2/3 compatibility\n",
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "# local modules\n",
    "from common import splitfn\n",
    "\n",
    "# built-in modules\n",
    "import os\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    import sys\n",
    "    import getopt\n",
    "    from glob import glob\n",
    "\n",
    "    args, img_mask = getopt.getopt(sys.argv[1:], '', ['debug=', 'square_size='])\n",
    "    args = dict(args)\n",
    "    args.setdefault('--debug', './output/')\n",
    "    args.setdefault('--square_size', 1.0)\n",
    "    if not img_mask:\n",
    "        img_mask = 'images/left*.jpg'  # default\n",
    "    else:\n",
    "        img_mask = img_mask[0]\n",
    "\n",
    "    img_names = glob(img_mask)\n",
    "    debug_dir = args.get('--debug')\n",
    "    if not os.path.isdir(debug_dir):\n",
    "        os.mkdir(debug_dir)\n",
    "    square_size = float(args.get('--square_size'))\n",
    "\n",
    "    pattern_size = (9, 6)\n",
    "    pattern_points = np.zeros((np.prod(pattern_size), 3), np.float32)\n",
    "    pattern_points[:, :2] = np.indices(pattern_size).T.reshape(-1, 2)\n",
    "    pattern_points *= square_size\n",
    "\n",
    "    obj_points = []\n",
    "    img_points = []\n",
    "    h, w = 0, 0\n",
    "    img_names_undistort = []\n",
    "    for fn in img_names:\n",
    "        print('processing %s... ' % fn, end='')\n",
    "        img = cv2.imread(fn, 0)\n",
    "        if img is None:\n",
    "            print(\"Failed to load\", fn)\n",
    "            continue\n",
    "\n",
    "        h, w = img.shape[:2]\n",
    "        found, corners = cv2.findChessboardCorners(img, pattern_size)\n",
    "        if found:\n",
    "            term = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_COUNT, 30, 0.1)\n",
    "            cv2.cornerSubPix(img, corners, (5, 5), (-1, -1), term)\n",
    "\n",
    "        if debug_dir:\n",
    "            vis = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)\n",
    "            cv2.drawChessboardCorners(vis, pattern_size, corners, found)\n",
    "            path, name, ext = splitfn(fn)\n",
    "            outfile = debug_dir + name + '_chess.png'\n",
    "            cv2.imwrite(outfile, vis)\n",
    "            if found:\n",
    "                img_names_undistort.append(outfile)\n",
    "\n",
    "        if not found:\n",
    "            print('chessboard not found')\n",
    "            continue\n",
    "\n",
    "        img_points.append(corners.reshape(-1, 2))\n",
    "        obj_points.append(pattern_points)\n",
    "\n",
    "        print('ok')\n",
    "\n",
    "    # calculate camera distortion\n",
    "    rms, camera_matrix, dist_coefs, rvecs, tvecs = cv2.calibrateCamera(obj_points, img_points, (w, h), None, None)\n",
    "\n",
    "    print(\"\\nRMS:\", rms)\n",
    "    print(\"camera matrix:\\n\", camera_matrix)\n",
    "    print(\"distortion coefficients: \", dist_coefs.ravel())\n",
    "\n",
    "    # undistort the image with the calibration\n",
    "    print('')\n",
    "    for img_found in img_names_undistort:\n",
    "        img = cv2.imread(img_found)\n",
    "\n",
    "        h,  w = img.shape[:2]\n",
    "        newcameramtx, roi = cv2.getOptimalNewCameraMatrix(camera_matrix, dist_coefs, (w, h), 1, (w, h))\n",
    "\n",
    "        dst = cv2.undistort(img, camera_matrix, dist_coefs, None, newcameramtx)\n",
    "\n",
    "        # crop and save the image\n",
    "        x, y, w, h = roi\n",
    "        dst = dst[y:y+h, x:x+w]\n",
    "        outfile = img_found + '_undistorted.png'\n",
    "        print('Undistorted image written to: %s' % outfile)\n",
    "        cv2.imwrite(outfile, dst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Re-projection Error:\n",
    "\n",
    "Re-projection error gives a good estimation of just how exact is the found parameters. This should be as close to zero as possible. Given the intrinsic, distortion, rotation and translation matrices, we first transform the object point to image point using cv2.projectPoints(). Then we calculate the absolute norm between what we got with our transformation and the corner finding algorithm. To find the average error we calculate the arithmetical mean of the errors calculate for all the calibration images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "mean_error = 0\n",
    "for i in xrange(len(objpoints)):\n",
    "    imgpoints2, _ = cv2.projectPoints(objpoints[i], rvecs[i], tvecs[i], mtx, dist)\n",
    "    error = cv2.norm(imgpoints[i],imgpoints2, cv2.NORM_L2)/len(imgpoints2)\n",
    "    tot_error += error\n",
    "    \n",
    "print \"total error: \", mean_error/len(objpoints)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Pose Estimation\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Here we will learn to exploit calib3d module to create some 3D effects in images.\n",
    "\n",
    "During the previous session on camera calibration, we found the camera matrix, distortion coefficients etc. Given a pattern image, we can utilize the above information to calculate its pose, or how the object is situated in space, like how it is rotated, how it is displaced etc. For a planar object, we can assume Z=0, such that, the problem now becomes how camera is placed in space to see our pattern image. So, if we know how the object lies in the space, we can draw some 2D diagrams in it to simulate the 3D effect. Let's see how to do it.\n",
    "\n",
    "Our problem is, we want to draw our 3D coordinate axis (X, Y, Z axes) on our chessboard's first corner. X axis in blue color, Y axis in green color and Z axis in red color. So in-effect, Z axis should feel like it is perpendicular to our chessboard plane.\n",
    "\n",
    "First, let's load the camera matrix and distortion coefficients from the previous calibration result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import glob\n",
    "# Load previously saved data\n",
    "with np.load('B.npz') as X:\n",
    "    mtx, dist, _, _ = [X[i] for i in ('mtx','dist','rvecs','tvecs')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Now letâ€™s create a function, draw which takes the corners in the chessboard (obtained using <a href=\"http://docs.opencv.org/3.0.0/d9/d0c/group__calib3d.html#ga93efa9b0aa890de240ca32b11253dd4a\">cv2.findChessboardCorners())</a> and axis points to draw a 3D axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def draw(img, corners, imgpts):\n",
    "    corner = tuple(corners[0].ravel())\n",
    "    img = cv2.line(img, corner, tuple(imgpts[0].ravel()), (255,0,0), 5)\n",
    "    img = cv2.line(img, corner, tuple(imgpts[1].ravel()), (0,255,0), 5)\n",
    "    img = cv2.line(img, corner, tuple(imgpts[2].ravel()), (0,0,255), 5)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Then as in previous case, we create termination criteria, object points (3D points of corners in chessboard) and axis\n",
    "points. Axis points are points in 3D space for drawing the axis. We draw axis of length 3 (units will be in terms of\n",
    "chess square size since we calibrated based on that size). So our X axis is drawn from (0,0,0) to (3,0,0), so for Y axis.\n",
    "For Z axis, it is drawn from (0,0,0) to (0,0,-3). Negative denotes it is drawn towards the camera."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 30, 0.001)\n",
    "objp = np.zeros((6*7,3), np.float32)\n",
    "objp[:,:2] = np.mgrid[0:7,0:6].T.reshape(-1,2)\n",
    "axis = np.float32([[3,0,0], [0,3,0], [0,0,-3]]).reshape(-1,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Now, as usual, we load each image. Search for 7x6 grid. If found, we refine it with subcorner pixels. Then to calculate\n",
    "the rotation and translation, we use the function, <a href=\"http://docs.opencv.org/3.0.0/d9/d0c/group__calib3d.html#ga50620f0e26e02caa2e9adc07b5fbf24e\">cv2.solvePnPRansac()</a>. Once we those transformation matrices,\n",
    "we use them to project our axis points to the image plane. In simple words, we find the points on image plane\n",
    "corresponding to each of (3,0,0),(0,3,0),(0,0,3) in 3D space. Once we get them, we draw lines from the first corner to\n",
    "each of these points using our draw() function. Done!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "for fname in glob.glob('left*.jpg'):\n",
    "    img = cv2.imread(fname)\n",
    "    gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    ret, corners = cv2.findChessboardCorners(gray, (7,6),None)\n",
    "    if ret == True:\n",
    "        corners2 = cv2.cornerSubPix(gray,corners,(11,11),(-1,-1),criteria)\n",
    "        \n",
    "        # Find the rotation and translation vectors.\n",
    "        rvecs, tvecs, inliers = cv2.solvePnPRansac(objp, corners2, mtx, dist)\n",
    "        \n",
    "        # project 3D points to image plane\n",
    "        imgpts, jac = cv2.projectPoints(axis, rvecs, tvecs, mtx, dist)\n",
    "        img = draw(img,corners2,imgpts)\n",
    "        cv2.imshow('img',img)\n",
    "        k = cv2.waitKey(0) & 0xff\n",
    "        if k == 's':\n",
    "            cv2.imwrite(fname[:6]+'.png', img)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "See some results below. Notice that each axis is 3 squares long.:\n",
    "\n",
    "<img src=\"images/pose_1.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "___\n",
    "## Render a Cube\n",
    "\n",
    "If you want to draw a cube, modify the draw() function and axis points as follows.\n",
    "\n",
    "Modified draw() function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def draw(img, corners, imgpts):\n",
    "    imgpts = np.int32(imgpts).reshape(-1,2)\n",
    "    \n",
    "    # draw ground floor in green\n",
    "    img = cv2.drawContours(img, [imgpts[:4]],-1,(0,255,0),-3)\n",
    "    \n",
    "    # draw pillars in blue color\n",
    "    for i,j in zip(range(4),range(4,8)):\n",
    "        img = cv2.line(img, tuple(imgpts[i]), tuple(imgpts[j]),(255),3)\n",
    "    \n",
    "    # draw top layer in red color\n",
    "    img = cv2.drawContours(img, [imgpts[4:]],-1,(0,0,255),3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Modified axis points. They are the 8 corners of a cube in 3D space:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "axis = np.float32([[0,0,0], [0,3,0], [3,3,0], [3,0,0], [0,0,-3],[0,3,-3],[3,3,-3],[3,0,-3] ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "And look at the result below:\n",
    "<img src=\"images/pose_2.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "If you are interested in graphics, augmented reality etc, you can use OpenGL to render more complicated figures.\n",
    "___"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
